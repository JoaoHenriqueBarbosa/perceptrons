# Perceptrons - Sistema Educacional de Redes Neurais

![Python](https://img.shields.io/badge/Python-3.12-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115.0-green)
![React](https://img.shields.io/badge/React-18-61dafb)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue)

Um sistema completo e interativo para aprender sobre **Perceptrons** (neurÃ´nios simples) atravÃ©s de experimentaÃ§Ã£o prÃ¡tica. Desenhe padrÃµes, treine modelos e veja as limitaÃ§Ãµes e capacidades de redes neurais bÃ¡sicas em tempo real.

## ğŸ“š O que sÃ£o Perceptrons?

O **Perceptron** Ã© o modelo mais bÃ¡sico de rede neural, inventado por Frank Rosenblatt em 1957. Ã‰ um classificador linear que aprende a separar padrÃµes em classes usando uma simples regra de aprendizado.

### Como Funciona:

```
Entrada (256 pixels) â†’ Pesos â†’ Soma Ponderada â†’ AtivaÃ§Ã£o (0 ou 1)
```

- **Entrada**: Grid 16Ã—16 achatada (256 valores)
- **Pesos**: Um peso para cada pixel
- **Soma**: `z = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚‚â‚…â‚†xâ‚‚â‚…â‚† + bias`
- **AtivaÃ§Ã£o**: Se `z â‰¥ 0` â†’ Classe 1, senÃ£o â†’ Classe 0

### MÃºltiplos NeurÃ´nios (CodificaÃ§Ã£o BinÃ¡ria):

Com **N neurÃ´nios**, podemos representar atÃ© **2^N classes**:
- 1 neurÃ´nio: 2 classes (0, 1)
- 2 neurÃ´nios: 4 classes (00, 01, 10, 11)
- 3 neurÃ´nios: 8 classes (000, 001, 010, 011, 100, 101, 110, 111)

Cada neurÃ´nio aprende uma "pergunta binÃ¡ria", e a combinaÃ§Ã£o identifica a classe!

## ğŸ¯ O que vocÃª vai aprender:

### âœ… Conceitos que FUNCIONAM:
- Perceptrons conseguem separar classes **linearmente separÃ¡veis**
- Com dados suficientes (10-20 exemplos/classe), convergem rapidamente
- MÃºltiplos neurÃ´nios podem codificar mÃºltiplas classes
- A importÃ¢ncia de **balanceamento de classes** no dataset

### âŒ LimitaÃ§Ãµes descobertas na prÃ¡tica:
- Perceptrons **NÃƒO** aprendem padrÃµes nÃ£o-lineares (ex: XOR)
- Classes muito similares (T, H, L) sÃ£o difÃ­ceis de distinguir
- Com apenas 1 classe no dataset, o modelo nÃ£o aprende nada Ãºtil
- Fronteiras lineares sÃ£o muito simples para problemas complexos

### ğŸ§  Insights importantes:
- **Dados > Algoritmo**: Com bons dados, atÃ© modelos simples funcionam
- **ExperimentaÃ§Ã£o Ã© aprendizado**: Ver o modelo errar ensina tanto quanto vÃª-lo acertar
- **Trade-offs**: Mais neurÃ´nios = mais classes, mas tambÃ©m mais complexidade

## ğŸš€ Como Rodar o Projeto

### PrÃ©-requisitos

- **Python 3.12+**
- **Node.js 18+** ou **Bun**
- **Git**

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/perceptrons.git
cd perceptrons
```

### 2. Backend (API Python)

```bash
cd backend

# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
source venv/bin/activate  # Linux/Mac
# OU
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Rodar a API
uvicorn main:app --reload
```

A API estarÃ¡ em: `http://localhost:8000`

### 3. Frontend (React + TypeScript)

Em outro terminal:

```bash
cd frontend

# Instalar dependÃªncias
bun install  # ou npm install

# Rodar o frontend
bun run dev  # ou npm run dev
```

O frontend estarÃ¡ em: `http://localhost:5173`

## ğŸ“– Como Usar

### 1. Dataset - Criar Exemplos de Treinamento

**Acesse:** `http://localhost:5173/dataset`

1. **Digite um label** (classe) no campo: `T`, `nÃ£o-T`, `H`, `L`, etc.
2. **Desenhe o padrÃ£o** na grid 16Ã—16:
   - Clique e arraste para desenhar
   - SÃ³ pinta pixels (nÃ£o apaga)
3. **Salve o exemplo** - Grid limpa automaticamente
4. **Repita** 10-20 vezes por classe

**Dicas:**
- Crie **variaÃ§Ãµes** (T largo, T fino, T torto)
- Mantenha **balanceamento** (mesma quantidade por classe)
- Use o botÃ£o **"Atualizar Labels sem classe"** para corrigir labels em massa

**EstatÃ­sticas:** Veja quantos exemplos vocÃª tem de cada classe!

### 2. Training - Treinar Modelos

**Acesse:** `http://localhost:5173/training`

1. **Configure o nÃºmero de neurÃ´nios:**
   - 1 neurÃ´nio = 2 classes (binÃ¡rio)
   - 2 neurÃ´nios = 4 classes
   - 3 neurÃ´nios = 8 classes
   - 4 neurÃ´nios = 16 classes

2. **Configure as Ã©pocas:** 10-500 iteraÃ§Ãµes
   - Modelo **converge** quando erro = 0
   - Se convergir rÃ¡pido (ex: 2 Ã©pocas), estÃ¡ aprendendo bem!

3. **Clique "Iniciar Treinamento"**

4. **Veja o resultado:**
   - AcurÃ¡cia
   - Ã‰pocas executadas
   - ConvergÃªncia
   - NÃºmero de classes detectadas

**Modelos sÃ£o salvos automaticamente** e aparecem na lista!

### 3. Test - Testar PadrÃµes

**Acesse:** `http://localhost:5173/test`

1. **Selecione um modelo treinado**
2. **Desenhe um padrÃ£o de teste**
3. **Clique "Testar PadrÃ£o"**
4. **Veja a prediÃ§Ã£o:**
   - Classe identificada
   - CÃ³digo binÃ¡rio dos neurÃ´nios

## ğŸ”¬ Experimentos Recomendados

### Experimento 1: ClassificaÃ§Ã£o BinÃ¡ria Simples
**Objetivo:** Ver o Perceptron funcionando perfeitamente

1. Crie 2 classes **muito diferentes**:
   - **Classe "T"**: 15 exemplos da letra T
   - **Classe "vazio"**: 15 exemplos de grids vazias

2. Treine com **1 neurÃ´nio**, **100 Ã©pocas**

3. Teste: Desenhe T â†’ retorna "T", Desenhe vazio â†’ retorna "vazio"

**Resultado esperado:** AcurÃ¡cia ~100%, convergÃªncia rÃ¡pida âœ“

### Experimento 2: MÃºltiplas Classes Distintas
**Objetivo:** Ver codificaÃ§Ã£o binÃ¡ria em aÃ§Ã£o

1. Crie 4 classes distintas:
   - Linha vertical
   - Linha horizontal
   - Diagonal /
   - Diagonal \

2. Treine com **2 neurÃ´nios** (2Â² = 4 classes)

3. Veja o mapeamento:
   - Vertical â†’ 00
   - Horizontal â†’ 01
   - Diagonal / â†’ 10
   - Diagonal \ â†’ 11

**Resultado esperado:** AcurÃ¡cia ~80-90% âœ“

### Experimento 3: Classes Similares (LimitaÃ§Ã£o)
**Objetivo:** Ver onde o Perceptron falha

1. Crie 3 classes similares:
   - **T**: 20 exemplos
   - **H**: 20 exemplos
   - **L**: 20 exemplos

2. Treine com **2 neurÃ´nios**

3. Teste: Provavelmente vai confundir as letras!

**Resultado esperado:** AcurÃ¡cia ~40-60%, muita confusÃ£o âœ—

**Por quÃª?** T, H, L sÃ£o muito parecidos. Perceptrons sÃ³ aprendem fronteiras lineares!

### Experimento 4: Dataset Desbalanceado
**Objetivo:** Ver importÃ¢ncia do balanceamento

1. Crie:
   - **T**: 50 exemplos
   - **nÃ£o-T**: 5 exemplos

2. Treine com **1 neurÃ´nio**

3. Teste: Modelo vai prever "T" para quase tudo!

**Resultado esperado:** Alta acurÃ¡cia aparente, mas modelo inÃºtil âœ—

## ğŸ“Š Estrutura do Projeto

```
perceptrons/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # API FastAPI
â”‚   â”œâ”€â”€ perceptron.py           # Classe Perceptron
â”‚   â”œâ”€â”€ multi_perceptron.py     # MÃºltiplos neurÃ´nios
â”‚   â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”‚   â”œâ”€â”€ patterns.db            # SQLite (criado automaticamente)
â”‚   â””â”€â”€ models/                # Modelos treinados (criado automaticamente)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx       # PÃ¡gina inicial
â”‚   â”‚   â”‚   â”œâ”€â”€ Dataset.tsx    # Criar dataset
â”‚   â”‚   â”‚   â”œâ”€â”€ Training.tsx   # Treinar modelos
â”‚   â”‚   â”‚   â””â”€â”€ Test.tsx       # Testar padrÃµes
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ router.tsx     # TanStack Router
â”‚   â”‚   â”œâ”€â”€ App.tsx            # App principal
â”‚   â”‚   â””â”€â”€ App.css            # Estilos
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ README.md
```

## ğŸ”§ Tecnologias Utilizadas

### Backend:
- **FastAPI** - Framework web moderno e rÃ¡pido
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **SQLite** - Banco de dados leve
- **Uvicorn** - Servidor ASGI

### Frontend:
- **React 18** - UI Library
- **TypeScript** - Tipagem estÃ¡tica
- **TanStack Router** - Roteamento
- **Vite** - Build tool
- **Bun** - Runtime JavaScript

## ğŸ“ API Endpoints

### PadrÃµes
- `POST /api/patterns` - Salvar novo padrÃ£o
- `GET /api/patterns` - Listar todos os padrÃµes
- `DELETE /api/patterns/{id}` - Deletar padrÃ£o
- `PUT /api/patterns/bulk-update-labels` - Atualizar labels em massa

### Treinamento
- `POST /api/train` - Treinar novo modelo
- `GET /api/models` - Listar modelos treinados

### PrediÃ§Ã£o
- `POST /api/predict` - Fazer prediÃ§Ã£o com modelo

## ğŸ“ Conceitos Aprendidos

### 1. Algoritmo de Aprendizado do Perceptron

```python
for epoch in range(epochs):
    for cada exemplo (x, y):
        prediÃ§Ã£o = predict(x)
        erro = y - prediÃ§Ã£o

        if erro != 0:
            # Ajustar pesos
            w = w + learning_rate Ã— erro Ã— x
            b = b + learning_rate Ã— erro
```

**IntuiÃ§Ã£o:** Se errou, ajusta os pesos na direÃ§Ã£o correta!

### 2. Separabilidade Linear

**Pode ser separado com Perceptron:**
```
Classe A: â—â—â—     |     Classe B:     â—‹â—‹â—‹
```

**NÃƒO pode ser separado com Perceptron (XOR):**
```
â— â—‹
â—‹ â—
```

Precisa de fronteira nÃ£o-linear â†’ Perceptron simples falha!

### 3. ConvergÃªncia

- Se classes sÃ£o linearmente separÃ¡veis â†’ **sempre converge**
- Se nÃ£o sÃ£o â†’ **nunca converge** (oscila indefinidamente)
- NÃºmero de Ã©pocas atÃ© convergÃªncia depende da complexidade

### 4. CodificaÃ§Ã£o BinÃ¡ria para MÃºltiplas Classes

Com 2 neurÃ´nios classificando 4 classes:

```
NeurÃ´nio 1    NeurÃ´nio 2    Classe
    0             0           A
    0             1           B
    1             0           C
    1             1           D
```

Cada neurÃ´nio aprende uma "pergunta" diferente!

## âš ï¸ LimitaÃ§Ãµes Conhecidas

### Do Perceptron:
- âŒ NÃ£o aprende padrÃµes nÃ£o-lineares
- âŒ SensÃ­vel a outliers
- âŒ Pode nÃ£o convergir com dados nÃ£o-separÃ¡veis
- âŒ Fronteiras de decisÃ£o muito simples

### Do Projeto:
- Grid fixa 16Ã—16 (256 features)
- Sem prÃ©-processamento de imagem
- Sem validaÃ§Ã£o cruzada
- Sem regularizaÃ§Ã£o
- Treinamento no conjunto completo (sem train/test split)

## ğŸš€ Melhorias Futuras

- [ ] Implementar MLP (Multi-Layer Perceptron) com backpropagation
- [ ] Adicionar visualizaÃ§Ã£o dos pesos aprendidos
- [ ] Train/test split automÃ¡tico
- [ ] GrÃ¡ficos de erro por Ã©poca
- [ ] Export de modelos para uso externo
- [ ] Importar imagens externas
- [ ] Data augmentation
- [ ] MÃ©tricas mais detalhadas (matriz de confusÃ£o, precisÃ£o, recall)

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Este Ã© um projeto educacional, entÃ£o fique Ã  vontade para:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

MIT License - Sinta-se livre para usar este projeto para aprender e ensinar!

## ğŸ™ Agradecimentos

- Frank Rosenblatt - Por inventar o Perceptron em 1957
- Comunidade Python e React por ferramentas incrÃ­veis
- VocÃª, por se interessar em aprender sobre redes neurais! ğŸ‰

## ğŸ“š Recursos Adicionais

- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) - Michael Nielsen
- [The Perceptron](https://en.wikipedia.org/wiki/Perceptron) - Wikipedia
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://react.dev/)

---

**Feito com â¤ï¸ para educaÃ§Ã£o em Machine Learning**

*"A melhor forma de aprender Ã© experimentar!"*
