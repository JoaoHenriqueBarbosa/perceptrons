# ğŸ§  Perceptrons - EvoluÃ§Ã£o de Redes Neurais Educacionais

Sistema educacional progressivo de redes neurais, desde perceptrons simples atÃ© MLPs com Human-in-the-Loop (HITL).

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.12-blue.svg)
![React](https://img.shields.io/badge/react-18-blue.svg)

---

## ğŸ“š Ãndice

1. [VisÃ£o Geral](#-visÃ£o-geral)
2. [EvoluÃ§Ã£o do Projeto](#-evoluÃ§Ã£o-do-projeto)
3. [Arquitetura](#-arquitetura)
4. [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
5. [Como Usar](#-como-usar)
6. [Conceitos Implementados](#-conceitos-implementados)
7. [Contribuindo](#-contribuindo)
8. [LicenÃ§a](#-licenÃ§a)

---

## ğŸ¯ VisÃ£o Geral

Este projeto Ã© uma jornada educacional completa atravÃ©s da evoluÃ§Ã£o das redes neurais, implementada do zero com foco em **compreensÃ£o** e **interatividade**. Cada etapa do projeto representa um marco histÃ³rico na evoluÃ§Ã£o das redes neurais.

### Por que este projeto existe?

- ğŸ“– **Educacional**: Entender redes neurais implementando do zero
- ğŸ”¬ **Experimental**: Interface visual para testar conceitos
- ğŸ¨ **Interativo**: Desenhe padrÃµes e veja a rede aprender
- ğŸ¤– **HITL**: Aprenda com feedback humano em tempo real

---

## ğŸš€ EvoluÃ§Ã£o do Projeto

### Fase 1: Single-Layer Perceptron (1957)
**Baseado no Perceptron de Rosenblatt**

```
single-layer-perceptron/
```

**O que foi implementado:**
- âœ… Perceptron binÃ¡rio simples (funÃ§Ã£o degrau)
- âœ… CodificaÃ§Ã£o binÃ¡ria para mÃºltiplas classes (N neurÃ´nios = 2^N classes)
- âœ… Algoritmo de aprendizado original de Rosenblatt
- âœ… Interface visual para desenhar padrÃµes 16Ã—16

**LimitaÃ§Ãµes:**
- âŒ Apenas problemas linearmente separÃ¡veis
- âŒ FunÃ§Ã£o de ativaÃ§Ã£o nÃ£o-diferenciÃ¡vel (degrau)
- âŒ NÃ£o pode aprender XOR ou padrÃµes nÃ£o-lineares

**Exemplo de uso:**
```bash
cd single-layer-perceptron/backend
./run.sh
```

**Aprendizado:**
- ConvergÃªncia garantida para problemas linearmente separÃ¡veis
- CodificaÃ§Ã£o binÃ¡ria criativa para mÃºltiplas classes
- Base histÃ³rica das redes neurais

---

### Fase 2: Multi-Layer Perceptron (1986)
**Baseado em Rumelhart, Hinton e Williams**

```
multi-layer-network/
```

**O que foi implementado:**
- âœ… MÃºltiplas camadas (entrada â†’ ocultas â†’ saÃ­da)
- âœ… FunÃ§Ã£o de ativaÃ§Ã£o Sigmoid (diferenciÃ¡vel)
- âœ… **Backpropagation** completo
- âœ… Mini-batch gradient descent
- âœ… Xavier/Glorot initialization
- âœ… Gradient clipping
- âœ… Early stopping
- âœ… Cross-entropy loss

**Arquitetura:**
```python
# Exemplo: 256 â†’ 64 â†’ 32 â†’ 2
MLP(layer_sizes=[256, 64, 32, 2], learning_rate=0.3)
```

**Melhorias sobre Single-Layer:**
- âœ… Aprende padrÃµes nÃ£o-lineares (XOR, cÃ­rculos, etc)
- âœ… RepresentaÃ§Ãµes hierÃ¡rquicas
- âœ… ConvergÃªncia mais robusta
- âœ… GeneralizaÃ§Ã£o melhorada

**Dataset Balanceado:**
- 442 exemplos de "T" (3 variaÃ§Ãµes de tamanho)
- 442 exemplos de "No-T" (8 letras + formas aleatÃ³rias)
- **882 amostras totais (50/50 balanceado)**

**TÃ©cnicas de Data Augmentation:**
```python
# Gera variaÃ§Ãµes deslocando padrÃ£o pixel-by-pixel
# T de 5Ã—5 â†’ 144 posiÃ§Ãµes (12Ã—12 grid)
# T de 3Ã—3 â†’ 196 posiÃ§Ãµes (14Ã—14 grid)
# T de 7Ã—7 â†’ 100 posiÃ§Ãµes (10Ã—10 grid)
```

---

### Fase 3: Multi-Layer with Human-in-the-Loop (2023+)
**Baseado em RLHF (ChatGPT) e Active Learning**

```
multi-layer-network-with-human-enforcement/
```

**O que foi implementado:**

#### 1ï¸âƒ£ **Active Learning**
Sistema pede feedback quando incerto (entropia > 30%)

```python
def predict_with_uncertainty(self, X):
    # Calcula entropia da distribuiÃ§Ã£o de probabilidades
    entropy = -Î£(p * log(p))
    uncertainty = entropy / max_entropy

    if uncertainty > threshold:
        return "PEDIR FEEDBACK HUMANO"
```

**Quando pedir feedback:**
- ğŸŸ¢ < 20% incerteza: Modelo confiante
- ğŸŸ  20-40%: Incerteza mÃ©dia
- ğŸ”´ > 40%: **Pedir feedback!**

#### 2ï¸âƒ£ **RLHF (Reinforcement Learning from Human Feedback)**
Ajusta pesos instantaneamente com correÃ§Ã£o humana

```python
def learn_from_feedback(self, X, correct_label):
    # 1. Forward propagation
    prediction = self.predict(X)

    # 2. Backpropagation com label correto
    gradients = self.backprop(X, correct_label)

    # 3. Update com learning rate MAIOR (0.5)
    self.weights -= 0.5 * gradients

    # 4. Salvar modelo atualizado
    self.save_model()
```

**DiferenÃ§a do treinamento normal:**
- LR maior (0.5 vs 0.1-0.3)
- Update imediato (nÃ£o espera epoch)
- Salva modelo apÃ³s cada feedback

#### 3ï¸âƒ£ **Feedback Tracking**
Sistema monitora evoluÃ§Ã£o com feedback humano

```python
# EstatÃ­sticas armazenadas
{
    'total_feedback': 45,
    'improvements': 38,
    'improvement_rate': 0.844,  # 84.4% das correÃ§Ãµes melhoraram
    'feedback_by_label': {
        'T': 22,
        'No-T': 23
    }
}
```

**Interface Visual:**
- ğŸ“Š Barra de incerteza colorida
- ğŸ¯ Active Learning alerts
- ğŸ“ˆ GrÃ¡fico de probabilidades
- âœï¸ FormulÃ¡rio de correÃ§Ã£o
- ğŸ“‰ EstatÃ­sticas em tempo real

---

## ğŸ—ï¸ Arquitetura

### Stack TecnolÃ³gico

**Backend:**
```
Python 3.12
â”œâ”€â”€ FastAPI (API REST)
â”œâ”€â”€ NumPy (ComputaÃ§Ã£o numÃ©rica)
â”œâ”€â”€ SQLite (PersistÃªncia)
â””â”€â”€ Uvicorn (Servidor ASGI)
```

**Frontend:**
```
React 18 + TypeScript
â”œâ”€â”€ Vite (Build tool)
â”œâ”€â”€ TanStack Router (Roteamento)
â””â”€â”€ CSS Modules (EstilizaÃ§Ã£o)
```

### Estrutura de DiretÃ³rios

```
perceptrons/
â”‚
â”œâ”€â”€ single-layer-perceptron/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ perceptron.py          # Perceptron simples
â”‚   â”‚   â”œâ”€â”€ multi_perceptron.py    # CodificaÃ§Ã£o binÃ¡ria
â”‚   â”‚   â”œâ”€â”€ main.py                # API FastAPI
â”‚   â”‚   â””â”€â”€ patterns.db            # Dataset
â”‚   â””â”€â”€ frontend/
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ pages/
â”‚           â”‚   â”œâ”€â”€ Dataset.tsx    # Criar padrÃµes
â”‚           â”‚   â”œâ”€â”€ Training.tsx   # Treinar modelo
â”‚           â”‚   â””â”€â”€ Test.tsx       # Testar modelo
â”‚           â””â”€â”€ App.tsx
â”‚
â”œâ”€â”€ multi-layer-network/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ mlp.py                 # MLP com backprop
â”‚   â”‚   â”œâ”€â”€ main.py                # API REST
â”‚   â”‚   â”œâ”€â”€ patterns.db            # Dataset balanceado (882)
â”‚   â”‚   â”œâ”€â”€ generate_variations.py # Data augmentation
â”‚   â”‚   â”œâ”€â”€ build_balanced_dataset.py
â”‚   â”‚   â””â”€â”€ models/                # Modelos treinados
â”‚   â””â”€â”€ frontend/
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ pages/
â”‚               â”œâ”€â”€ Training.tsx   # Config hiperparÃ¢metros
â”‚               â””â”€â”€ Test.tsx
â”‚
â””â”€â”€ multi-layer-network-with-human-enforcement/
    â”œâ”€â”€ backend/
    â”‚   â”œâ”€â”€ mlp.py                 # MLP base
    â”‚   â”œâ”€â”€ mlp_hitl.py            # MLP + HITL â­
    â”‚   â”œâ”€â”€ main.py                # API com endpoints HITL
    â”‚   â””â”€â”€ patterns.db            # Dataset + feedback
    â””â”€â”€ frontend/
        â””â”€â”€ src/
            â””â”€â”€ pages/
                â””â”€â”€ TestHITL.tsx   # Interface HITL â­
```

---

## ğŸ’» InstalaÃ§Ã£o

### PrÃ©-requisitos

```bash
# Python 3.12+
python3 --version

# Node.js 18+
node --version
```

### Setup RÃ¡pido

**1. Clone o repositÃ³rio:**
```bash
git clone https://github.com/seu-usuario/perceptrons.git
cd perceptrons
```

**2. Escolha qual versÃ£o rodar:**

#### OpÃ§Ã£o A: Single-Layer Perceptron
```bash
# Backend
cd single-layer-perceptron/backend
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
./run.sh  # ou: uvicorn main:app --reload

# Frontend (novo terminal)
cd ../frontend
npm install
npm run dev
```

#### OpÃ§Ã£o B: Multi-Layer Perceptron
```bash
# Backend
cd multi-layer-network/backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
./run.sh

# Frontend
cd ../frontend
npm install
npm run dev
```

#### OpÃ§Ã£o C: MLP with HITL â­
```bash
# Backend
cd multi-layer-network-with-human-enforcement/backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
./run.sh

# Frontend
cd ../frontend
npm install
npm run dev
```

**3. Acesse:**
- Frontend: http://localhost:5173
- API: http://localhost:8000
- Docs: http://localhost:8000/docs

---

## ğŸ® Como Usar

### 1. Single-Layer Perceptron

**Passo a passo:**

1. **Dataset** (`/dataset`)
   - Desenhe padrÃµes 16Ã—16
   - Rotule como "T" ou outra letra
   - Salve mÃºltiplos exemplos

2. **Training** (`/training`)
   - Escolha nÃºmero de neurÃ´nios (1-4)
   - Configure Ã©pocas (padrÃ£o: 100)
   - Inicie treinamento
   - Veja codificaÃ§Ã£o binÃ¡ria gerada

3. **Test** (`/test`)
   - Selecione modelo treinado
   - Desenhe padrÃ£o
   - Veja prediÃ§Ã£o + cÃ³digo binÃ¡rio

### 2. Multi-Layer Perceptron

**Dataset Balanceado (jÃ¡ incluÃ­do):**
- âœ… 442 exemplos de "T"
- âœ… 442 exemplos de "No-T"
- âœ… VariaÃ§Ãµes automÃ¡ticas (data augmentation)

**Treinamento:**

```python
# HiperparÃ¢metros recomendados
{
    "hidden_layers": [64, 32],      # 256â†’64â†’32â†’2
    "learning_rate": 0.3,            # LR alto converge rÃ¡pido
    "batch_size": 16,                # Mini-batch
    "epochs": 300                    # Early stopping ativo
}
```

**Resultados esperados:**
- AcurÃ¡cia: 95-100%
- ConvergÃªncia: ~100-200 Ã©pocas
- Loss final: < 0.05

### 3. MLP with Human-in-the-Loop

**Workflow:**

1. **Treinar modelo base** (`/training`)
   - Use dataset balanceado
   - Configure arquitetura (ex: 64,32)
   - Treine atÃ© ~95% acurÃ¡cia

2. **Testar com HITL** (`/test-hitl`)
   - Desenhe padrÃ£o
   - Sistema mostra:
     - PrediÃ§Ã£o
     - Incerteza (%)
     - Probabilidades por classe
     - Alert se incerto

3. **Fornecer Feedback**
   - Se prediÃ§Ã£o errada â†’ Corrigir
   - Sistema aplica RLHF imediatamente
   - Modelo salvo automaticamente
   - Veja estatÃ­sticas atualizadas

**MÃ©tricas HITL:**
```json
{
  "total_feedback": 50,
  "improvements": 42,
  "improvement_rate": 0.84,  // 84% melhoraram
  "feedback_by_label": {
    "T": 25,
    "No-T": 25
  }
}
```

---

## ğŸ“– Conceitos Implementados

### Algoritmos

#### 1. Perceptron Learning Rule (1957)
```python
# Para cada exemplo (x, y):
prediction = sign(wÂ·x + b)
if prediction != y:
    w = w + Î· * y * x
    b = b + Î· * y
```

#### 2. Backpropagation (1986)
```python
# Forward pass
for layer in layers:
    z = W @ a + b
    a = sigmoid(z)

# Backward pass
Î´_L = (a_L - y) âŠ™ Ïƒ'(z_L)
for layer in reversed(layers):
    âˆ‡W = a^T @ Î´ / m
    âˆ‡b = sum(Î´) / m
    Î´ = (Î´ @ W^T) âŠ™ Ïƒ'(a)

# Update
W = W - Î· * âˆ‡W
b = b - Î· * âˆ‡b
```

#### 3. Active Learning (2000s)
```python
# Entropy-based uncertainty
H(p) = -Î£ p_i * log(p_i)
uncertainty = H(p) / log(K)  # Normalizado

if uncertainty > threshold:
    request_human_feedback()
```

#### 4. RLHF (2020s)
```python
# Recebe correÃ§Ã£o humana
correct_label = human_input()

# Backprop com label correto
loss = cross_entropy(prediction, correct_label)
gradients = backward(loss)

# Update com LR maior
weights -= 0.5 * gradients  # vs 0.1 normal
save_model()
```

### TÃ©cnicas de OtimizaÃ§Ã£o

| TÃ©cnica | ImplementaÃ§Ã£o | BenefÃ­cio |
|---------|--------------|-----------|
| Xavier Init | `w ~ U[-âˆš(6/(n_in+n_out)), +âˆš(6/(n_in+n_out))]` | Evita vanishing/exploding gradients |
| Gradient Clipping | `if â€–âˆ‡wâ€– > 5: âˆ‡w = âˆ‡w * (5/â€–âˆ‡wâ€–)` | Estabiliza treinamento |
| Early Stopping | Para se val_loss nÃ£o melhora por 50 Ã©pocas | Previne overfitting |
| Mini-batch | Batch size 16-32 | BalanÃ§a velocidade e estabilidade |

### Data Augmentation

```python
# Gera variaÃ§Ãµes deslocando padrÃ£o
def generate_variations(pattern):
    for row in range(max_positions_y):
        for col in range(max_positions_x):
            if (row, col) != original_position:
                yield shift_pattern(pattern, row, col)

# Exemplo: T de 5Ã—5
# Grid 16Ã—16 permite posiÃ§Ãµes: (16-5+1) Ã— (16-5+1) = 12Ã—12 = 144
# Menos posiÃ§Ã£o original = 143 variaÃ§Ãµes
```

---

## ğŸ“Š Resultados

### Single-Layer Perceptron

**Problema: Classificar "T" vs "No-T"**

| MÃ©trica | Valor |
|---------|-------|
| Dataset | 62 exemplos (manual) |
| AcurÃ¡cia | ~70-80% |
| LimitaÃ§Ã£o | Aprende apenas 1 feature (ex: "pixels no topo") |

**ConclusÃ£o:** Insuficiente para padrÃµes complexos.

### Multi-Layer Perceptron

**Mesmo problema com dataset balanceado**

| MÃ©trica | Valor |
|---------|-------|
| Dataset | 882 exemplos (balanceado 50/50) |
| Arquitetura | 256â†’64â†’32â†’2 |
| AcurÃ¡cia | **95-100%** âœ… |
| Loss final | 0.015-0.050 |
| Ã‰pocas | ~100-200 (early stop) |

**ConclusÃ£o:** Aprende representaÃ§Ãµes complexas!

### MLP with HITL

**EvoluÃ§Ã£o contÃ­nua com feedback**

| MÃ©trica | Inicial | ApÃ³s 50 Feedbacks |
|---------|---------|-------------------|
| AcurÃ¡cia | 95% | **98-99%** |
| Casos incertos | 15% | **5%** |
| Taxa de melhoria | - | 84% |

**ConclusÃ£o:** Feedback humano elimina erros residuais!

---

## ğŸ“ Aprendizados

### 1. Por que Single-Layer falha?

**Problema XOR:**
```
Input: (0,0) â†’ 0
Input: (0,1) â†’ 1
Input: (1,0) â†’ 1
Input: (1,1) â†’ 0
```

NÃ£o existe linha reta que separe estas classes! Perceptron simples nÃ£o consegue.

### 2. Como MLP resolve?

**Camadas ocultas criam representaÃ§Ãµes:**
```
Camada 1: Detecta bordas
Camada 2: Detecta formas
Camada 3: Detecta letras
```

Transforma problema nÃ£o-linear em linear no espaÃ§o de features.

### 3. Por que HITL melhora?

**Active Learning:**
- Foca em exemplos difÃ­ceis
- Humano fornece conhecimento onde modelo falha

**RLHF:**
- CorreÃ§Ã£o instantÃ¢nea
- Aprende padrÃµes que treinamento offline perdeu

---

## ğŸ› ï¸ Scripts Ãšteis

### Data Augmentation
```bash
cd multi-layer-network/backend
python3 generate_variations.py
# Gera variaÃ§Ãµes de padrÃµes deslocados
```

### Construir Dataset Balanceado
```bash
python3 build_balanced_dataset.py
# Combina Ts + No-Ts em proporÃ§Ã£o 50/50
```

### Analisar Dataset
```bash
python3 analyze_dataset.py
# Mostra distribuiÃ§Ã£o, variÃ¢ncia, separabilidade
```

### Testar MLP Standalone
```bash
python3 mlp.py
# Interface CLI para treinar e testar
```

### Testar HITL Standalone
```bash
python3 mlp_hitl.py
# Demo de Active Learning + RLHF
```

---

## ğŸ› Troubleshooting

### Backend nÃ£o inicia

```bash
# Verificar Python
python3 --version  # Deve ser 3.12+

# Recriar venv
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Frontend erro de CORS

```bash
# Verificar se backend estÃ¡ rodando
curl http://localhost:8000/

# Verificar porta correta
# Backend: 8000
# Frontend: 5173
```

### Modelo nÃ£o converge

```python
# Ajustar hiperparÃ¢metros
{
    "learning_rate": 0.3,      # Aumentar se muito lento
    "batch_size": 16,          # Diminuir se instÃ¡vel
    "hidden_layers": [64, 32]  # Simplificar arquitetura
}
```

### Dataset desbalanceado

```bash
# Reconstruir dataset balanceado
python3 build_balanced_dataset.py
```

---

## ğŸ“š ReferÃªncias

### Papers ClÃ¡ssicos

1. **Rosenblatt, F. (1957)**
   - "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain"
   - Psychological Review

2. **Minsky & Papert (1969)**
   - "Perceptrons" (livro que mostrou limitaÃ§Ãµes)

3. **Rumelhart, Hinton & Williams (1986)**
   - "Learning representations by back-propagating errors"
   - Nature

4. **Glorot & Bengio (2010)**
   - "Understanding the difficulty of training deep feedforward neural networks"
   - AISTATS

### Conceitos Modernos

5. **Christiano et al. (2017)**
   - "Deep Reinforcement Learning from Human Preferences"
   - NeurIPS

6. **Ouyang et al. (2022)**
   - "Training language models to follow instructions with human feedback" (ChatGPT)
   - OpenAI

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Veja [CONTRIBUTING.md](CONTRIBUTING.md)

**Ideias para contribuir:**

- ğŸ¨ Novos datasets (nÃºmeros, formas, etc)
- ğŸ§ª FunÃ§Ãµes de ativaÃ§Ã£o (ReLU, tanh, etc)
- ğŸ“Š VisualizaÃ§Ã£o de pesos/ativaÃ§Ãµes
- ğŸ¯ Novos algoritmos (Dropout, Batch Norm, etc)
- ğŸ“± Interface mobile
- ğŸŒ Outros idiomas

---

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE)

---

## ğŸ‘ Agradecimentos

- Frank Rosenblatt - Inventor do Perceptron
- Geoffrey Hinton - Pai do Deep Learning
- Yann LeCun - Pioneiro em CNNs
- OpenAI - InspiraÃ§Ã£o para RLHF

---

## ğŸ“¬ Contato

**Projeto:** Sistema Educacional de Perceptrons
**Objetivo:** Ensinar redes neurais atravÃ©s de implementaÃ§Ã£o prÃ¡tica

---

<p align="center">
  Feito com â¤ï¸ e ğŸ§  por estudantes, para estudantes
</p>

<p align="center">
  <i>"The best way to learn is to build" - Andrew Ng</i>
</p>
